# -*- coding: utf-8 -*-
"""Thesis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-75AV5U_vI3zMPwzrD5cYhrErQPiHm_c
"""

pip install captum

"""### **Objective:**
Using a pretrained large language model to answer questions and using the **Captum** (https://captum.ai/) library to visualize which parts of the input text influenced the model's predictions the most.

### **Model and Tools Used:**
**BERT Model**: Used a variant of BERT that has been specifically fine-tuned on the Stanford Question Answering Dataset (SQuAD). This model is designed to answer questions based on the context provided.

**Transformers Library**: Used Hugging Face's transformers library to load the pretrained BERT model and tokenizer.

**Captum Library**: Used Captum’s **LayerIntegratedGradients** for explainability, which is used to understand the contributions of each input token to the model's output decisions.
"""

import torch
from transformers import BertTokenizer, BertForQuestionAnswering
from captum.attr import LayerIntegratedGradients
import matplotlib.pyplot as plt

# Loading pretrained model and tokenizer
model_name = 'bert-large-uncased-whole-word-masking-finetuned-squad'
tokenizer = BertTokenizer.from_pretrained(model_name)
model = BertForQuestionAnswering.from_pretrained(model_name)
model.eval()  # Setting the model to evaluation mode

# Defining a forward function for LayerIntegratedGradients
def forward_func(input_ids, attention_mask):
    return model(input_ids=input_ids, attention_mask=attention_mask)[0]

""" Used the BERT tokenizer to convert the question and the context into a format suitable for the model, generating input IDs and attention masks.Fed the tokenized input into the model to obtain logits(pre activation values) representing the start and end positions of the answer within the context text."""

# Sample data: question and context
question = "What is the capital of France?"
text = "Paris is the most populous city of France."
inputs = tokenizer(question, text, return_tensors='pt')

# Applying model and getting predictions
with torch.no_grad():
    outputs = model(**inputs)
    answer_start_scores, answer_end_scores = outputs.start_logits, outputs.end_logits

"""extracted the answer by using the positions with the highest logits to slice the input IDs, which were then converted back to text using the tokenizer."""

# Getting the most likely beginning and end of answer with the argmax of the scores
answer_start = torch.argmax(answer_start_scores)
answer_end = torch.argmax(answer_end_scores) + 1
answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][answer_start:answer_end]))

print("Answer:", answer)

# Setting up and computing attributions using LayerIntegratedGradients
lig = LayerIntegratedGradients(forward_func, model.bert.embeddings)
baseline = torch.zeros_like(inputs['input_ids'])
attributions, delta = lig.attribute(inputs=(inputs['input_ids'], inputs['attention_mask']),
                                    baselines=(baseline, baseline),
                                    target=answer_start,
                                    return_convergence_delta=True)

# Visualization
tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])
attributions_sum = attributions.sum(dim=-1).squeeze().detach().numpy()

plt.figure(figsize=(15, 5))
plt.plot(attributions_sum, label='Attribution Scores')
plt.xticks(range(len(tokens)), tokens, rotation=90)
plt.grid(True)
plt.legend()
plt.title("Visualizing Text Influence on the Answer")
plt.show()

import torch
from transformers import BertTokenizer, BertForQuestionAnswering
from captum.attr import LayerConductance
import matplotlib.pyplot as plt

# Load pretrained model and tokenizer
model_name = 'bert-large-uncased-whole-word-masking-finetuned-squad'
tokenizer = BertTokenizer.from_pretrained(model_name)
model = BertForQuestionAnswering.from_pretrained(model_name)
model.eval()  # Set the model to evaluation mode

# Prepare the input
question = "What is the capital of France?"
text = "Paris is the capital and most populous city of France."
inputs = tokenizer(question, text, return_tensors='pt')
input_ids = inputs['input_ids'].to(torch.long)  # Ensure tensor is of type torch.long

# Define the forward function to get output logits
def forward_func(input_ids):
    # Ensure the input IDs are long type as expected by embedding layers
    input_ids = input_ids.type(torch.long)
    outputs = model(input_ids=input_ids)
    return outputs.start_logits  # Focus on start logits for attribution

# Select an attention layer and initialize LayerConductance
attention_layer = model.bert.encoder.layer[0].attention.self
lc = LayerConductance(forward_func, attention_layer)

# Compute attributions for the start position logits
attributions_start = lc.attribute(inputs=input_ids, target=0)  # Focusing on the start logit

# Sum the attributions across the embedding dimension and visualize
attributions_sum = attributions_start.sum(dim=-1).squeeze(0).detach().numpy()
tokens = tokenizer.convert_ids_to_tokens(input_ids[0])

plt.figure(figsize=(15, 5))
plt.plot(attributions_sum, label='Layer Conductance')
plt.xticks(range(len(tokens)), tokens, rotation=90)
plt.xlabel('Token Position')
plt.ylabel('Attribution')
plt.title('Attribution of Tokens to Start Logit by Layer Conductance')
plt.legend()
plt.show()

"""# *APPLICATION OF TCAV*

# ***Sentiment Analysis for Financial Market Predictions***


---



### **Problem Statement:**
*How do different sources of sentiment (e.g., news articles, social media, analyst reports) influence AI-driven financial market predictions?*

### **Context and Importance:**

LLMs can analyze vast amounts of textual data to gauge market sentiment, which is a crucial factor in predicting stock prices, currency movements, or commodity prices. Different sources of sentiment may have varying impacts on market predictions, and it's important to understand how these sources contribute to the final prediction.


### **Analysis Goal:**
Will use a LLM to perform sentiment analysis on financial news, social media posts, and analyst reports. The LLM can generate a composite sentiment score for different assets (stocks, currencies, etc.).

**TCAV Analysis:** Will apply TCAV to determine how much influence different sources of sentiment (e.g., Twitter vs. Bloomberg news) have on the model’s predictions. This can help identify if the model is over-reliant on one type of sentiment source, which could skew predictions.

### **Loading and preprocessing the data:**
"""

import pandas as pd
import torch
from transformers import BartTokenizer, BartForConditionalGeneration
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import numpy as np
import pickle
import os

# Load the financial news dataset
news_data = pd.read_csv(os.path.join('/news_data', 'Combined_News_DJIA.csv'))

# Load the Twitter financial dataset
twitter_data = pd.read_csv(os.path.join('/twitter_data', 'tweet_sentiment.csv'))

# Check the data to ensure it's loaded correctly
print(twitter_data.head())

# Preview the datasets
print(news_data.head())
print(twitter_data.head())

# Preprocess the news dataset
# Here, we combine all the headlines for a given day into a single text entry
news_data['Combined_News'] = news_data.filter(regex="Top.*").apply(lambda x: ' '.join(x.dropna().astype(str)), axis=1)
news_data = news_data[['Date', 'Combined_News']]
news_data = news_data.dropna()

# Preprocess the Twitter dataset
twitter_data = twitter_data[['sentiment', 'cleaned_tweets']]  # Adjusted column names
twitter_data = twitter_data.dropna()

from google.colab import drive
drive.mount('/content/drive')

"""### **Performing Sentiment Analysis and Generating Embeddings:**
We’ll use BERT embeddings to represent the text data from both news and Twitter datasets.

"""

import torch
import numpy as np
from transformers import BertTokenizer, BertModel
import os

# Load pre-trained BERT tokenizer and model
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
model = BertModel.from_pretrained('bert-base-uncased')

# Enable GPU if available
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

# Function to generate and save embeddings batch by batch
def get_and_save_embeddings_batch(texts, output_file, batch_size=64):
    # Check if an existing file with embeddings exists
    if os.path.exists(output_file):
        saved_embeddings = np.load(output_file)
        start_batch = len(saved_embeddings) // batch_size
        print(f"Resuming from batch {start_batch + 1}")
    else:
        saved_embeddings = np.array([]).reshape(0, 768)  # Assuming BERT base with 768-dimensional embeddings
        start_batch = 0

    total_batches = len(texts) // batch_size + (1 if len(texts) % batch_size != 0 else 0)

    for i in range(start_batch * batch_size, len(texts), batch_size):
        batch_texts = texts[i:i + batch_size]
        inputs = tokenizer(batch_texts, return_tensors='pt', max_length=128, truncation=True, padding=True)
        inputs = {key: value.to(device) for key, value in inputs.items()}

        with torch.no_grad():
            outputs = model(**inputs)
            batch_embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()
            saved_embeddings = np.vstack([saved_embeddings, batch_embeddings])

        # Save the current state of embeddings after each batch
        np.save(output_file, saved_embeddings)
        if(i%10 == 0):
          print(f"Processed and saved batch {i//batch_size + 1}/{total_batches}")

    return saved_embeddings

# Example usage with progress markers and batch saving
news_texts = news_data['Combined_News'].tolist()
news_embeddings = get_and_save_embeddings_batch(news_texts, 'news_embeddings.npy')

twitter_texts = twitter_data['cleaned_tweets'].tolist()
twitter_embeddings = get_and_save_embeddings_batch(twitter_texts, 'twitter_embeddings.npy')

import numpy as np

news_embeddings = np.load('/news_data/news_embeddings.npy')
twitter_embeddings = np.load('twitter_embeddings.npy')

# Check the shape of the loaded embeddings to confirm they were loaded correctly
print(f"Shape of the loaded embeddings: {news_embeddings.shape}")
print(f"Shape of the loaded embeddings: {twitter_embeddings.shape}")

"""### **Creating CAVs and Calculating TCAV Scores:**
We’ll create Concept Activation Vectors (CAVs) for positive and negative sentiment for both datasets.
"""

# from sklearn.linear_model import LogisticRegression
# import numpy as np

# # Separate positive and negative sentiment data for Twitter
# twitter_positive = twitter_data[twitter_data['sentiment'] == 1].tolist()
# twitter_negative = twitter_data[twitter_data['sentiment'] == -1].tolist()

# # Assume the news dataset sentiment is overall positive as it contains market-moving news
# news_positive = news_data['embeddings'].tolist()
# news_negative = []  # We assume there is no explicitly negative news dataset here

# # Function to create a CAV
# def create_cav(positive_embeddings, negative_embeddings):
#     X = np.array(positive_embeddings + negative_embeddings)
#     y = np.array([1] * len(positive_embeddings) + [0] * len(negative_embeddings))
#     cav_model = LogisticRegression(solver='lbfgs').fit(X, y)
#     return cav_model.coef_

# # Create CAVs for news and Twitter sentiment
# cav_news = create_cav(news_positive, news_negative)
# cav_twitter = create_cav(twitter_positive, twitter_negative)


from sklearn.linear_model import LogisticRegression

# Create CAVs using a different solver (saga)
def create_cav_with_solver(positive_embeddings, negative_embeddings, solver='saga', max_iter=5000):
    X = np.vstack([positive_embeddings, negative_embeddings])
    y = np.array([1] * len(positive_embeddings) + [0] * len(negative_embeddings))

    cav_model = LogisticRegression(solver=solver, max_iter=max_iter).fit(X, y)
    return cav_model.coef_

# Create CAV for Twitter sentiment using 'saga' solver
cav_twitter = create_cav_with_solver(twitter_positive, twitter_negative, solver='saga', max_iter=5000)





"""### **Calculating and Visualizing TCAV Scores:**"""

# Function to calculate TCAV scores
def calculate_tcav_scores(embeddings, cav):
    tcav_scores = []
    for embedding in embeddings:
        score = np.dot(embedding, cav.T)
        tcav_scores.append(score[0])
    return np.array(tcav_scores)

# Calculate TCAV scores for news and Twitter sentiment
tcav_scores_news = calculate_tcav_scores(news_embeddings, cav_news)
tcav_scores_twitter = calculate_tcav_scores(twitter_embeddings, cav_twitter)

# Add TCAV scores back to the dataframes
news_data['tcav_score'] = tcav_scores_news
twitter_data['tcav_score'] = tcav_scores_twitter

# Visualize the TCAV scores
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(14, 7))

sns.histplot(tcav_scores_news, kde=True, color='blue', label='News Sentiment')
sns.histplot(tcav_scores_twitter, kde=True, color='green', label='Twitter Sentiment')

plt.title('TCAV Scores Distribution: News vs Twitter Sentiment Influence on Market Predictions')
plt.xlabel('TCAV Score')
plt.ylabel('Density')
plt.legend()
plt.show()

"""### **Summary:**
Applied TCAV to analyze the influence of different sentiment sources (news articles vs. social media) on financial market predictions using existing datasets. By visualizing the distribution of TCAV scores, we can gain insights into how much each sentiment source affects the model's predictions, this will allow us to identify potential biases and ensure a more balanced market forecasting approach.
"""

import matplotlib.pyplot as plt
import seaborn as sns

# Calculate the mean TCAV score for each sentiment source
mean_twitter_tcav = np.mean(tcav_scores_twitter)
mean_news_tcav = np.mean(tcav_scores_news)

# Data for the bar plot
mean_scores = [mean_news_tcav, mean_twitter_tcav]
labels = ['News Sentiment', 'Twitter Sentiment']

# Create a bar plot showing the mean TCAV scores
plt.figure(figsize=(10, 6))
sns.barplot(x=labels, y=mean_scores, palette=['blue', 'green'])

# Annotate the mean scores on the bars
for i, score in enumerate(mean_scores):
    plt.text(i, score + 0.1, f'{score:.2f}', ha='center', va='bottom', fontsize=12)

# Add titles and labels
plt.title('Mean TCAV Score: News vs Twitter Sentiment Influence')
plt.xlabel('Sentiment Source')
plt.ylabel('Mean TCAV Score')

# Show the plot
plt.show()

import torch
from transformers import BartTokenizer, BartForConditionalGeneration
from sklearn.linear_model import LogisticRegression
import numpy as np
import pickle
import os
import pandas as pd

# Load the BART model and tokenizer for feature extraction
tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')
model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')

# Step 1: Load the Bias in Bios Dataset
# You can replace this with any dataset that you're analyzing for bias
# For simplicity, let's assume we have a CSV file where 'biography' is the text and 'gender' is the label
data = pd.read_csv('/path_to_bias_in_bios.csv')  # Adjust the path
data = data[['biography', 'gender']]  # Assuming the dataset has a 'biography' and 'gender' column

# Step 2: Define Gender Concepts
# Gender-related phrases for male and female
male_phrases = ["he", "man", "male", "his", "him"]
female_phrases = ["she", "woman", "female", "her", "hers"]

# Step 3: Generate Concept Activations
def get_activations(phrases):
    activations = []
    for phrase in phrases:
        inputs = tokenizer(phrase, return_tensors='pt', max_length=512, truncation=True)
        outputs = model.model.encoder(**inputs)
        activations.append(outputs.last_hidden_state.mean(dim=1).detach().numpy())
    return np.array(activations).squeeze()

# Get activations for male, female, and random control
male_activations = get_activations(male_phrases)
female_activations = get_activations(female_phrases)
random_phrases = ["random", "words", "not", "related", "concepts"]
random_activations = get_activations(random_phrases)

# Step 4: Train Logistic Regression to Create CAVs
X = np.vstack([male_activations, female_activations, random_activations])
y = np.array([1]*len(male_activations) + [2]*len(female_activations) + [0]*len(random_activations))

# Train a Logistic Regression model to create the CAVs
cav_model = LogisticRegression(multi_class='ovr', solver='lbfgs').fit(X, y)
cavs = cav_model.coef_

# Save the CAVs for future use
os.makedirs('cavs', exist_ok=True)
with open('cavs/cav_gender.pkl', 'wb') as f:
    pickle.dump(cavs, f)

# Step 5: Calculate TCAV Scores
def calculate_tcav_scores(model, tokenizer, sentences, cavs):
    tcav_scores = {'male': 0, 'female': 0}
    for sentence in sentences:
        inputs = tokenizer(sentence, return_tensors='pt', max_length=512, truncation=True)
        outputs = model.model.encoder(**inputs)
        activations = outputs.last_hidden_state.mean(dim=1).detach().numpy().squeeze()

        grads = np.gradient(activations)
        for i, (concept, cav) in enumerate(zip(['male', 'female'], cavs)):
            dot_product = np.dot(grads, cav)
            if dot_product > 0:
                tcav_scores[concept] += 1

    total = sum(tcav_scores.values())
    for concept in tcav_scores:
        tcav_scores[concept] /= total if total != 0 else 1  # Normalize to percentages

    return tcav_scores

# Step 6: Test the Model and Compute TCAV on a Subset of Biographies
test_sentences = data['biography'].sample(100).tolist()  # Adjust sample size as needed
tcav_scores = calculate_tcav_scores(model, tokenizer, test_sentences, cavs)

print("TCAV Scores (Gender):", tcav_scores)

import torch
from transformers import BartTokenizer, BartForConditionalGeneration
from sklearn.linear_model import LogisticRegression
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import pickle
import os

# Load the dataset (you've loaded the Bias in Bios dataset using pandas)
splits = {
    'train': 'data/train-00000-of-00001-0ab65b32c47407e8.parquet',
    'test': 'data/test-00000-of-00001-5598c840ce8de1ee.parquet',
    'dev': 'data/dev-00000-of-00001-e6551072fff26949.parquet'
}

# Load data using pandas
train_df = pd.read_parquet("hf://datasets/LabHC/bias_in_bios/" + splits["train"])
test_df = pd.read_parquet("hf://datasets/LabHC/bias_in_bios/" + splits["test"])
dev_df = pd.read_parquet("hf://datasets/LabHC/bias_in_bios/" + splits["dev"])

# Step 1: Initialize the tokenizer and BART model
tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')
model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')

# Step 2: Define Gender Concepts (male and female phrases)
male_phrases = ["he", "man", "male", "his", "him"]
female_phrases = ["she", "woman", "female", "her", "hers"]

# Step 3: Generate Concept Activations
def get_activations(phrases):
    activations = []
    for phrase in phrases:
        inputs = tokenizer(phrase, return_tensors='pt', max_length=512, truncation=True)
        outputs = model.model.encoder(**inputs)
        activations.append(outputs.last_hidden_state.mean(dim=1).detach().numpy())
    return np.array(activations).squeeze()

# Get activations for male, female, and random (control) phrases
male_activations = get_activations(male_phrases)
female_activations = get_activations(female_phrases)
random_phrases = ["random", "words", "not", "related", "concepts"]
random_activations = get_activations(random_phrases)

# Step 4: Train Logistic Regression to Create CAVs
X = np.vstack([male_activations, female_activations, random_activations])
y = np.array([1]*len(male_activations) + [2]*len(female_activations) + [0]*len(random_activations))

# Train Logistic Regression model to create the CAVs
cav_model = LogisticRegression(multi_class='ovr', solver='lbfgs').fit(X, y)
cavs = cav_model.coef_

# Save the CAVs for future use
os.makedirs('cavs', exist_ok=True)
with open('cavs/cav_gender.pkl', 'wb') as f:
    pickle.dump(cavs, f)

# Step 5: Calculate TCAV Scores
def calculate_tcav_scores(model, tokenizer, sentences, cavs):
    tcav_scores = {'male': 0, 'female': 0}
    for sentence in sentences:
        inputs = tokenizer(sentence, return_tensors='pt', max_length=512, truncation=True)
        outputs = model.model.encoder(**inputs)
        activations = outputs.last_hidden_state.mean(dim=1).detach().numpy().squeeze()

        grads = np.gradient(activations)
        for i, (concept, cav) in enumerate(zip(['male', 'female'], cavs)):
            dot_product = np.dot(grads, cav)
            if dot_product > 0:
                tcav_scores[concept] += 1

    total = sum(tcav_scores.values())
    for concept in tcav_scores:
        tcav_scores[concept] /= total if total != 0 else 1  # Normalize to percentages

    return tcav_scores

# Step 6: Calculate TCAV Scores by Occupation
tcav_scores_by_occupation = {}

# List of unique occupations
occupations = train_df['occupation'].unique()

for occupation in occupations:
    # Extract biographies for the given occupation
    occupation_data = train_df[train_df['occupation'] == occupation]
    test_sentences = occupation_data['biography'].tolist()

    # Calculate TCAV scores for male and female concepts
    tcav_scores = calculate_tcav_scores(model, tokenizer, test_sentences, cavs)

    # Store the scores for this occupation
    tcav_scores_by_occupation[occupation] = tcav_scores

# Step 7: Calculate Gender Gap and % Female for Each Occupation
gender_gaps = []
female_proportions = []
occupation_names = []

for occupation, tcav_score in tcav_scores_by_occupation.items():
    # Calculate gender gap (difference between male and female TCAV scores)
    gender_gap = tcav_score['male'] - tcav_score['female']
    gender_gaps.append(gender_gap)

    # Calculate the proportion of females in this occupation
    total = len(train_df[train_df['occupation'] == occupation])
    females = len(train_df[(train_df['occupation'] == occupation) & (train_df['gender'] == 'female')])
    female_proportion = females / total if total > 0 else 0
    female_proportions.append(female_proportion)

    # Store the occupation name for annotation
    occupation_names.append(occupation)

# Step 8: Plot Gender Gap vs % Female
plt.figure(figsize=(10, 6))

# Create scatter plot
plt.scatter(female_proportions, gender_gaps, marker='o')

# Annotate each point with the occupation name
for i, occupation in enumerate(occupation_names):
    plt.text(female_proportions[i], gender_gaps[i], occupation, fontsize=9)

# Add labels and title
plt.xlabel('% Female')
plt.ylabel('TCAV Gender Gap (Male - Female)')
plt.title('Gender Gap per Occupation vs. % Females')

# Show the plot
plt.show()

import torch
from transformers import BartTokenizer, BartForConditionalGeneration
from sklearn.linear_model import LogisticRegression
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import pickle
import os

# Loading the dataset using pandas
splits = {
    'train': 'data/train-00000-of-00001-0ab65b32c47407e8.parquet',
    'test': 'data/test-00000-of-00001-5598c840ce8de1ee.parquet',
    'dev': 'data/dev-00000-of-00001-e6551072fff26949.parquet'
}

# Loading data using pandas
train_df = pd.read_parquet("hf://datasets/LabHC/bias_in_bios/" + splits["train"])
test_df = pd.read_parquet("hf://datasets/LabHC/bias_in_bios/" + splits["test"])
dev_df = pd.read_parquet("hf://datasets/LabHC/bias_in_bios/" + splits["dev"])

# Step 1: Initializing the tokenizer and BART model
tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')
model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')

# Step 2: Defining Gender Concepts (male and female phrases)
male_phrases = ["he", "man", "male", "his", "him"]
female_phrases = ["she", "woman", "female", "her", "hers"]

# Step 3: Method to generate Concept Activations
def get_activations(phrases):
    activations = []
    for phrase in phrases:
        inputs = tokenizer(phrase, return_tensors='pt', max_length=512, truncation=True)
        outputs = model.model.encoder(**inputs)
        activations.append(outputs.last_hidden_state.mean(dim=1).detach().numpy())
    return np.array(activations).squeeze()

# Get activations for male, female, and random (control) phrases
male_activations = get_activations(male_phrases)
female_activations = get_activations(female_phrases)
random_phrases = ["random", "words", "not", "related", "concepts"]
random_phrases2 = ["Mountain", "Bicycle", "Laptop", "Coffee", "River", "Bookstore", "Elephant", "Telescope", "Architecture",
"Astronomy", "Guitar", "Puzzle", "Cinema", "Clouds", "Algorithm", "Backpack", "Photography", "Chemistry",
"Volcano", "Gardening", "Piano", "Football", "Sunshine", "Galaxy", "Sandbox", "Snowflake", "Castle",
"Chocolate", "Subway", "Microwave", "Ocean", "Jungle", "Orchestra", "Newspaper", "Physics", "Sculpture",
"Satellite", "Windmill", "Dinosaur", "Calendar", "Meditation", "Symphony", "Pirate", "Postcard", "Forest",
"Typewriter", "Robot", "Calendar", "Marshmallow", "Origami"]
random_activations = get_activations(random_phrases)

# Step 4: Train Logistic Regression to Create CAVs
X = np.vstack([male_activations, female_activations, random_activations])
y = np.array([1]*len(male_activations) + [2]*len(female_activations) + [0]*len(random_activations))

# Train Logistic Regression model to create the CAVs
cav_model = LogisticRegression(multi_class='ovr', solver='lbfgs').fit(X, y)
cavs = cav_model.coef_

# Save the CAVs for future use
os.makedirs('cavs', exist_ok=True)
with open('cavs/cav_gender.pkl', 'wb') as f:
    pickle.dump(cavs, f)

# Step 5: Calculate TCAV Scores
def calculate_tcav_scores(model, tokenizer, sentences, cavs):
    tcav_scores = {'male': 0, 'female': 0}
    for sentence in sentences:
        inputs = tokenizer(sentence, return_tensors='pt', max_length=512, truncation=True)
        outputs = model.model.encoder(**inputs)
        activations = outputs.last_hidden_state.mean(dim=1).detach().numpy().squeeze()

        grads = np.gradient(activations)
        for i, (concept, cav) in enumerate(zip(['male', 'female'], cavs)):
            dot_product = np.dot(grads, cav)
            if dot_product > 0:
                tcav_scores[concept] += 1

    total = sum(tcav_scores.values())
    for concept in tcav_scores:
        tcav_scores[concept] /= total if total != 0 else 1  # Normalize to percentages

    return tcav_scores

# Step 6: Calculate TCAV Scores by Occupation
tcav_scores_by_occupation = {}

# List of unique occupations
occupations = train_df['profession'].unique()

for occupation in occupations:
    # Extract biographies for the given occupation
    occupation_data = train_df[train_df['profession'] == occupation]
    test_sentences = occupation_data['hard_text'].tolist()

    # Calculate TCAV scores for male and female concepts
    tcav_scores = calculate_tcav_scores(model, tokenizer, test_sentences, cavs)

    # Store the scores for this occupation
    tcav_scores_by_occupation[occupation] = tcav_scores

# Step 7: Calculate Gender Gap and % Female for Each Occupation
gender_gaps = []
female_proportions = []
occupation_names = []

for occupation, tcav_score in tcav_scores_by_occupation.items():
    # Calculate gender gap (difference between male and female TCAV scores)
    gender_gap = tcav_score['male'] - tcav_score['female']
    gender_gaps.append(gender_gap)

    # Calculate the proportion of females in this occupation
    total = len(train_df[train_df['profession'] == occupation])
    females = len(train_df[(train_df['profession'] == occupation) & (train_df['gender'] == 'female')])
    female_proportion = females / total if total > 0 else 0
    female_proportions.append(female_proportion)

    # Store the occupation name for annotation
    occupation_names.append(occupation)

# Step 8: Plot Gender Gap vs % Female
plt.figure(figsize=(10, 6))

# Create scatter plot
plt.scatter(female_proportions, gender_gaps, marker='o')

# Annotate each point with the occupation name
for i, occupation in enumerate(occupation_names):
    plt.text(female_proportions[i], gender_gaps[i], occupation, fontsize=9)

# Add labels and title
plt.xlabel('% Female')
plt.ylabel('TCAV Gender Gap (Male - Female)')
plt.title('Gender Gap per Occupation vs. % Females')

# Show the plot
plt.show()

train_df.columns

occupation_data.columns



import torch
from transformers import BartTokenizer, BartForConditionalGeneration
from sklearn.linear_model import LogisticRegression
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import pickle
import os

# Loading the dataset using pandas
splits = {
    'train': 'data/train-00000-of-00001-0ab65b32c47407e8.parquet',
    'test': 'data/test-00000-of-00001-5598c840ce8de1ee.parquet',
    'dev': 'data/dev-00000-of-00001-e6551072fff26949.parquet'
}

# Loading data using pandas
train_df = pd.read_parquet("hf://datasets/LabHC/bias_in_bios/" + splits["train"])
test_df = pd.read_parquet("hf://datasets/LabHC/bias_in_bios/" + splits["test"])
dev_df = pd.read_parquet("hf://datasets/LabHC/bias_in_bios/" + splits["dev"])

# Step 1: Initializing the tokenizer and BART model
tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')
model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')

# Step 2: Defining Gender Concepts (male and female phrases)
male_phrases = ["he", "man", "male", "his", "him"]
female_phrases = ["she", "woman", "female", "her", "hers"]

# Step 3: Method to generate Concept Activations
def get_activations(phrases):
    activations = []
    for phrase in phrases:
        inputs = tokenizer(phrase, return_tensors='pt', max_length=512, truncation=True)
        outputs = model.model.encoder(**inputs)
        activations.append(outputs.last_hidden_state.mean(dim=1).detach().numpy())
    return np.array(activations).squeeze()

# Get activations for male, female, and random (control) phrases
male_activations = get_activations(male_phrases)
female_activations = get_activations(female_phrases)
random_phrases = ["random", "words", "not", "related", "concepts","Laptop", "Coffee","Physics", "Sculpture", "Architecture"]
random_phrases2 = ["Mountain", "Bicycle", "Laptop", "Coffee", "River", "Bookstore", "Elephant", "Telescope", "Architecture",
"Astronomy", "Guitar", "Puzzle", "Cinema", "Clouds", "Algorithm", "Backpack", "Photography", "Chemistry",
"Volcano", "Gardening", "Piano", "Football", "Sunshine", "Galaxy", "Sandbox", "Snowflake", "Castle",
"Chocolate", "Subway", "Microwave", "Ocean", "Jungle", "Orchestra", "Newspaper", "Physics", "Sculpture",
"Satellite", "Windmill", "Dinosaur", "Calendar", "Meditation", "Symphony", "Pirate", "Postcard", "Forest",
"Typewriter", "Robot", "Calendar", "Marshmallow", "Origami"]
random_activations = get_activations(random_phrases)

# Step 4: Train Logistic Regression to Create CAVs
X = np.vstack([male_activations, female_activations, random_activations])
y = np.array([1]*len(male_activations) + [2]*len(female_activations) + [0]*len(random_activations))

# Train Logistic Regression model to create the CAVs
cav_model = LogisticRegression(multi_class='ovr', solver='lbfgs').fit(X, y)
cavs = cav_model.coef_

# Save the CAVs for future use
os.makedirs('cavs', exist_ok=True)
with open('cavs/cav_gender.pkl', 'wb') as f:
    pickle.dump(cavs, f)

from tqdm import tqdm

# Helper function to chunk the data into mini-batches
def batch_data(sentences, batch_size):
    for i in range(0, len(sentences), batch_size):
        yield sentences[i:i + batch_size]

# Step 5: Calculate TCAV Scores with Mini-Batches
def calculate_tcav_scores_in_batches(model, tokenizer, sentences, cavs, batch_size=32):
    tcav_scores = {'male': 0, 'female': 0}
    total_sentences = len(sentences)

    # Initialize tqdm progress bar for sentence processing
    with tqdm(total=total_sentences, desc="Calculating TCAV scores in mini-batches", ncols=100) as pbar:
        for batch in batch_data(sentences, batch_size):
            # Tokenize the batch
            inputs = tokenizer(batch, return_tensors='pt', padding=True, max_length=512, truncation=True)
            outputs = model.model.encoder(**inputs)
            activations = outputs.last_hidden_state.mean(dim=1).detach().numpy()

            grads = np.gradient(activations, axis=0)  # Calculate gradients for the batch
            for i, (concept, cav) in enumerate(zip(['male', 'female'], cavs)):
                dot_product = np.dot(grads, cav)
                tcav_scores[concept] += np.sum(dot_product > 0)

            # Update the progress bar after processing each mini-batch
            pbar.update(len(batch))

    total = sum(tcav_scores.values())
    for concept in tcav_scores:
        tcav_scores[concept] /= total if total != 0 else 1  # Normalize to percentages

    return tcav_scores

# Step 6: Calculate TCAV Scores by Occupation with Mini-Batches
tcav_scores_by_occupation = {}

# List of unique occupations
occupations = train_df['profession'].unique()

for occupation in occupations:
    # Extract biographies for the given occupation
    occupation_data = train_df[train_df['profession'] == occupation]
    test_sentences = occupation_data['hard_text'].tolist()

    # Calculate TCAV scores for male and female concepts in mini-batches
    tcav_scores = calculate_tcav_scores_in_batches(model, tokenizer, test_sentences, cavs, batch_size=32)

    # Store the scores for this occupation
    tcav_scores_by_occupation[occupation] = tcav_scores

# Step 7: Calculate Gender Gap and % Female for Each Occupation
gender_gaps = []
female_proportions = []
occupation_names = []

for occupation, tcav_score in tcav_scores_by_occupation.items():
    # Calculate gender gap (difference between male and female TCAV scores)
    gender_gap = tcav_score['male'] - tcav_score['female']
    gender_gaps.append(gender_gap)

    # Calculate the proportion of females in this occupation
    total = len(train_df[train_df['profession'] == occupation])
    females = len(train_df[(train_df['profession'] == occupation) & (train_df['gender'] == 'female')])
    female_proportion = females / total if total > 0 else 0
    female_proportions.append(female_proportion)

    # Store the occupation name for annotation
    occupation_names.append(occupation)

# Step 8: Plot Gender Gap vs % Female
plt.figure(figsize=(10, 6))

# Create scatter plot
plt.scatter(female_proportions, gender_gaps, marker='o')

# Annotate each point with the occupation name
for i, occupation in enumerate(occupation_names):
    plt.text(female_proportions[i], gender_gaps[i], occupation, fontsize=9)

# Add labels and title
plt.xlabel('% Female')
plt.ylabel('TCAV Gender Gap (Male - Female)')
plt.title('Gender Gap per Occupation vs. % Females')

# Show the plot
plt.show()

import torch
from transformers import BartTokenizer, BartForConditionalGeneration
from sklearn.linear_model import LogisticRegression
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import pickle
import os

# Loading the dataset using pandas
splits = {
    'train': 'data/train-00000-of-00001-0ab65b32c47407e8.parquet',
    'test': 'data/test-00000-of-00001-5598c840ce8de1ee.parquet',
    'dev': 'data/dev-00000-of-00001-e6551072fff26949.parquet'
}

# Loading data using pandas
train_df = pd.read_parquet("hf://datasets/LabHC/bias_in_bios/" + splits["train"])
test_df = pd.read_parquet("hf://datasets/LabHC/bias_in_bios/" + splits["test"])
dev_df = pd.read_parquet("hf://datasets/LabHC/bias_in_bios/" + splits["dev"])

# Step 1: Initializing the tokenizer and BART model
tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')
model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')

# Step 2: Defining Gender Concepts (male and female phrases)
male_phrases = ["he", "man", "male", "his", "him"]
female_phrases = ["she", "woman", "female", "her", "hers"]

# Step 3: Method to generate Concept Activations
def get_activations(phrases):
    activations = []
    for phrase in phrases:
        inputs = tokenizer(phrase, return_tensors='pt', max_length=512, truncation=True)
        outputs = model.model.encoder(**inputs)
        activations.append(outputs.last_hidden_state.mean(dim=1).detach().numpy())
    return np.array(activations).squeeze()

# Get activations for male, female, and random (control) phrases
male_activations = get_activations(male_phrases)
female_activations = get_activations(female_phrases)
random_phrases = ["random", "words", "not", "related", "concepts","Laptop", "Coffee","Physics", "Sculpture", "Architecture"]
random_phrases2 = ["Mountain", "Bicycle", "Laptop", "Coffee", "River", "Bookstore", "Elephant", "Telescope", "Architecture",
"Astronomy", "Guitar", "Puzzle", "Cinema", "Clouds", "Algorithm", "Backpack", "Photography", "Chemistry",
"Volcano", "Gardening", "Piano", "Football", "Sunshine", "Galaxy", "Sandbox", "Snowflake", "Castle",
"Chocolate", "Subway", "Microwave", "Ocean", "Jungle", "Orchestra", "Newspaper", "Physics", "Sculpture",
"Satellite", "Windmill", "Dinosaur", "Calendar", "Meditation", "Symphony", "Pirate", "Postcard", "Forest",
"Typewriter", "Robot", "Calendar", "Marshmallow", "Origami"]
random_activations = get_activations(random_phrases)

# Step 4: Train Logistic Regression to Create CAVs
X = np.vstack([male_activations, female_activations, random_activations])
y = np.array([1]*len(male_activations) + [2]*len(female_activations) + [0]*len(random_activations))

# Train Logistic Regression model to create the CAVs
cav_model = LogisticRegression(multi_class='ovr', solver='lbfgs').fit(X, y)
cavs = cav_model.coef_

# Save the CAVs for future use
os.makedirs('cavs', exist_ok=True)
with open('cavs/cav_gender.pkl', 'wb') as f:
    pickle.dump(cavs, f)
import random
from tqdm import tqdm

# Helper function to shuffle and chunk the data into mini-batches
def batch_data_randomized(sentences, batch_size):
    # Shuffle sentences before creating batches
    random.shuffle(sentences)
    for i in range(0, len(sentences), batch_size):
        yield sentences[i:i + batch_size]

# Step 5: Calculate TCAV Scores with Randomized Mini-Batches
def calculate_tcav_scores_with_random_batches(model, tokenizer, sentences, cavs, batch_size=32):
    tcav_scores = {'male': 0, 'female': 0}
    total_sentences = len(sentences)

    # Initialize tqdm progress bar for sentence processing
    with tqdm(total=total_sentences, desc="Calculating TCAV scores with randomized batches", ncols=100) as pbar:
        for batch in batch_data_randomized(sentences, batch_size):
            # Tokenize the batch
            inputs = tokenizer(batch, return_tensors='pt', padding=True, max_length=512, truncation=True)
            outputs = model.model.encoder(**inputs)
            activations = outputs.last_hidden_state.mean(dim=1).detach().numpy()

            grads = np.gradient(activations, axis=0)  # Calculate gradients for the batch
            for i, (concept, cav) in enumerate(zip(['male', 'female'], cavs)):
                dot_product = np.dot(grads, cav)
                tcav_scores[concept] += np.sum(dot_product > 0)

            # Update the progress bar after processing each mini-batch
            pbar.update(len(batch))

    total = sum(tcav_scores.values())
    for concept in tcav_scores:
        tcav_scores[concept] /= total if total != 0 else 1  # Normalize to percentages

    return tcav_scores

# Step 6: Calculate TCAV Scores by Occupation with Randomized Mini-Batches
tcav_scores_by_occupation = {}

# List of unique occupations
occupations = train_df['profession'].unique()

for occupation in occupations:
    # Extract biographies for the given occupation
    occupation_data = train_df[train_df['profession'] == occupation]
    test_sentences = occupation_data['hard_text'].tolist()

    # Calculate TCAV scores for male and female concepts in randomized mini-batches
    tcav_scores = calculate_tcav_scores_with_random_batches(model, tokenizer, test_sentences, cavs, batch_size=32)

    # Store the scores for this occupation
    tcav_scores_by_occupation[occupation] = tcav_scores

# Step 7: Calculate Gender Gap and % Female for Each Occupation
gender_gaps = []
female_proportions = []
occupation_names = []

for occupation, tcav_score in tcav_scores_by_occupation.items():
    # Calculate gender gap (difference between male and female TCAV scores)
    gender_gap = tcav_score['male'] - tcav_score['female']
    gender_gaps.append(gender_gap)

    # Calculate the proportion of females in this occupation
    total = len(train_df[train_df['profession'] == occupation])
    females = len(train_df[(train_df['profession'] == occupation) & (train_df['gender'] == 'female')])
    female_proportion = females / total if total > 0 else 0
    female_proportions.append(female_proportion)

    # Store the occupation name for annotation
    occupation_names.append(occupation)

# Step 8: Plot Gender Gap vs % Female
plt.figure(figsize=(10, 6))

# Create scatter plot
plt.scatter(female_proportions, gender_gaps, marker='o')

# Annotate each point with the occupation name
for i, occupation in enumerate(occupation_names):
    plt.text(female_proportions[i], gender_gaps[i], occupation, fontsize=9)

# Add labels and title
plt.xlabel('% Female')
plt.ylabel('TCAV Gender Gap (Male - Female)')
plt.title('Gender Gap per Occupation vs. % Females')

# Show the plot
plt.show()

tcav_scores_by_occupation

"""## *Analyzing Topic Influence in News Headline Generation*

*How do specific topics, such as politics, technology, or sports, influence the output of a headline generation model, and does the model show any bias towards certain topics when generating headlines?*

### **Analysis Goals:**
  
*   To understand whether a headline generation model, like BART, is more influenced by certain topics when generating headlines from news articles.
*   To evaluate if the model exhibits a bias by generating more attention-grabbing headlines for certain topics, potentially skewing the perceived importance of the news.




### **'Concepts' used for analysis:**
Politics: Words or phrases related to politics, such as "election," "government," "policy," etc.
Technology: Words or phrases related to technology, such as "AI," "blockchain," "innovation," etc.
Sports: Words or phrases related to sports, such as "football," "Olympics," "tournament," etc.
"""

import torch
from transformers import BartTokenizer, BartForConditionalGeneration
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import numpy as np
import pickle
import os

# Step 1: Load the Dataset
# Assuming you have downloaded the News Category Dataset and extracted it
import pandas as pd

data = pd.read_json('/content/News_Category_Dataset_v2.json', lines=True)
data = data[['headline', 'short_description', 'category']]

# Focus on the main topics for simplicity
data = data[data['category'].isin(['POLITICS', 'TECH', 'SPORTS'])]

# Step 2: Load the Pre-trained BART Model for Headline Generation
tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')
model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')

# Step 3: Define Concepts
# Define phrases related to Politics, Technology, and Sports
politics_phrases = ["government", "election", "policy", "president", "congress"]
tech_phrases = ["AI", "technology", "blockchain", "innovation", "software"]
sports_phrases = ["football", "Olympics", "tournament", "goal", "team"]

# Generate concept activations by passing these phrases through the model
def get_activations(phrases):
    activations = []
    for phrase in phrases:
        inputs = tokenizer(phrase, return_tensors='pt', max_length=512, truncation=True)
        outputs = model.model.encoder(**inputs)
        activations.append(outputs.last_hidden_state.mean(dim=1).detach().numpy())
    return np.array(activations).squeeze()

politics_activations = get_activations(politics_phrases)
tech_activations = get_activations(tech_phrases)
sports_activations = get_activations(sports_phrases)

# Random phrases for control
random_phrases = ["random", "words", "not", "related", "concepts"]
random_activations = get_activations(random_phrases)

# Step 4: Generating CAVs
# We label the concepts as 1 and random activations as 0
X = np.vstack([politics_activations, tech_activations, sports_activations, random_activations])
y = np.array([1]*len(politics_activations) + [2]*len(tech_activations) + [3]*len(sports_activations) + [0]*len(random_activations))

# Train a Logistic Regression model to create the CAV
cav_model = LogisticRegression(multi_class='ovr', solver='lbfgs').fit(X, y)
cavs = cav_model.coef_

# Save the CAVs for future use
os.makedirs('cavs', exist_ok=True)
with open('cavs/cav.pkl', 'wb') as f:
    pickle.dump(cavs, f)

# Step 5: Calculate TCAV Scores
# We'll compute the gradients of the model's output w.r.t. the activations and use them to calculate TCAV scores

def calculate_tcav_scores(model, tokenizer, sentences, cavs):
    tcav_scores = {'politics': 0, 'tech': 0, 'sports': 0}
    for sentence in sentences:
        inputs = tokenizer(sentence, return_tensors='pt', max_length=512, truncation=True)
        outputs = model.model.encoder(**inputs)
        activations = outputs.last_hidden_state.mean(dim=1).detach().numpy().squeeze()

        grads = np.gradient(activations)
        for i, (concept, cav) in enumerate(zip(['politics', 'tech', 'sports'], cavs)):
            dot_product = np.dot(grads, cav)
            if dot_product > 0:
                tcav_scores[concept] += 1

    total = sum(tcav_scores.values())
    for concept in tcav_scores:
        tcav_scores[concept] /= total

    return tcav_scores

# Example test sentences from the dataset
test_sentences = data['short_description'].sample(100).tolist()

tcav_scores = calculate_tcav_scores(model, tokenizer, test_sentences, cavs)
print("TCAV Scores:", tcav_scores)

import matplotlib.pyplot as plt
import seaborn as sns

# Visualization using matplotlib and seaborn
def plot_tcav_scores(tcav_scores):
    concepts = list(tcav_scores.keys())
    scores = list(tcav_scores.values())

    plt.figure(figsize=(10, 6))
    sns.barplot(x=concepts, y=scores, palette="viridis")

    plt.title("TCAV Scores: Influence of Topics on Headline Generation", fontsize=16)
    plt.xlabel("Concepts (Topics)", fontsize=14)
    plt.ylabel("Normalized TCAV Score", fontsize=14)
    plt.ylim(0, 1)  # Since scores are normalized, they should be between 0 and 1
    plt.show()

# Plot the TCAV scores
plot_tcav_scores(tcav_scores)